# openai_client.py

import logging
import os
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

# Attempt to import the new v1.x client
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    logger.warning("OpenAI library not available (v1.x)")
    OpenAI = None
    OPENAI_AVAILABLE = False


class OpenAIClient:
    """Client for OpenAI API operations (v1.x interface)."""

    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
        self.max_tokens = int(os.getenv("OPENAI_MAX_TOKENS", "500"))
        self.temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.7"))
        self.top_p = float(os.getenv("OPENAI_TOP_P", "0.9"))
        self.frequency_penalty = float(os.getenv("OPENAI_FREQUENCY_PENALTY", "0.5"))
        self.presence_penalty = float(os.getenv("OPENAI_PRESENCE_PENALTY", "0.3"))

        self.system_prompt = os.getenv(
            "SYSTEM_PROMPT",
            """You are a medical assistant whose responses must:
1. Directly address the user's question.
2. Use bullet points or numbered lists where appropriate.
3. Stay under 200 words.
4. Never provide speculative advice—only factual, evidence-based information."""
        )

        # Only initialize if library is present and API key is set
        if self.is_available():
            self._initialize_client()

    def is_available(self) -> bool:
        """Check if OpenAI v1.x is available and API key is configured."""
        return OPENAI_AVAILABLE and bool(self.api_key)

    def _initialize_client(self):
        """Initialize the v1.x OpenAI client."""
        if not self.is_available():
            return

        try:
            self._client = OpenAI(api_key=self.api_key)
            logger.info("OpenAI v1.x client initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI v1.x client: {e}")
            self._client = None

    def generate_response(
        self,
        messages: List[Dict[str, str]],
        session_id: str
    ) -> str:
        """
        Generate response using OpenAI Chat Completions API.
        
        Args:
            messages: List of message dicts with 'role' and 'content' keys
            session_id: Session identifier for logging
            
        Returns:
            Generated response text
        """
        if not self.is_available() or self._client is None:
            return "OpenAI API is not available. Please check your API key configuration."

        try:
            # Validate messages format
            if not messages or not isinstance(messages, list):
                return "Invalid message format provided."
            
            # Ensure all messages have proper format
            formatted_messages = []
            for msg in messages:
                if not isinstance(msg, dict) or 'role' not in msg or 'content' not in msg:
                    logger.warning(f"Skipping invalid message: {msg}")
                    continue
                    
                # FIXED: Use simple string content, not array format
                formatted_messages.append({
                    "role": msg["role"],
                    "content": str(msg["content"])  # Ensure content is a string
                })
            
            if not formatted_messages:
                return "No valid messages to process."

            # Limit message history to prevent token overflow
            if len(formatted_messages) > 20:
                # Keep system message (first) and last 19 messages
                system_msg = formatted_messages[0] if formatted_messages[0]["role"] == "system" else None
                recent_messages = formatted_messages[-19:]
                
                if system_msg and recent_messages[0]["role"] != "system":
                    formatted_messages = [system_msg] + recent_messages
                else:
                    formatted_messages = recent_messages

            logger.info(f"Sending {len(formatted_messages)} messages to OpenAI for session {session_id}")

            response = self._client.chat.completions.create(
                model=self.model,
                messages=formatted_messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                top_p=self.top_p,
                frequency_penalty=self.frequency_penalty,
                presence_penalty=self.presence_penalty
            )

            if not response.choices or not response.choices[0].message:
                return "No response generated by the AI model."

            response_text = response.choices[0].message.content
            if not response_text:
                return "Empty response received from AI model."

            return response_text.strip()

        except Exception as e:
            err_str = str(e)
            logger.error(f"OpenAI v1.x API error for session {session_id}: {err_str}")

            # Provide user-friendly error messages
            if "Rate limit" in err_str or "429" in err_str:
                return "I'm experiencing high demand right now. Please try again in a moment."
            elif "Authentication" in err_str or "Invalid API key" in err_str or "401" in err_str:
                return "Authentication error. Please check the API key configuration."
            elif "Invalid request" in err_str or "400" in err_str:
                return "I encountered an error processing your request. Please try rephrasing your question."
            elif "context_length_exceeded" in err_str or "maximum context length" in err_str:
                return "Your message is too long. Please try with a shorter question."
            elif "timeout" in err_str or "connection" in err_str.lower():
                return "Connection timeout. Please try again in a moment."
            else:
                return "I'm having trouble connecting to the AI service. Please try again later."

    def test_connection(self) -> Dict[str, Any]:
        """Test the OpenAI API connection."""
        if not self.is_available():
            return {
                "connected": False,
                "error": "OpenAI v1.x not available or API key not configured"
            }

        if self._client is None:
            return {
                "connected": False,
                "error": "OpenAI client not initialized"
            }

        try:
            # FIXED: Use simple string content format
            response = self._client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello"}
                ],
                max_tokens=10
            )
            
            return {
                "connected": True,
                "model": self.model,
                "response_preview": response.choices[0].message.content[:50] if response.choices else "No response"
            }
        except Exception as e:
            return {
                "connected": False,
                "error": str(e)
            }

    def get_model_info(self) -> Dict[str, Any]:
        """Return basic configuration info about the current OpenAI model."""
        return {
            "available": self.is_available(),
            "client_initialized": hasattr(self, '_client') and self._client is not None,
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": self.top_p,
            "frequency_penalty": self.frequency_penalty,
            "presence_penalty": self.presence_penalty,
            "system_prompt_length": len(self.system_prompt) if self.system_prompt else 0
        }

    def estimate_tokens(self, text: str) -> int:
        """Very rough token estimate (1 token ≈ 4 characters)."""
        if not text:
            return 0
        return len(str(text)) // 4

    def validate_message_length(
        self,
        messages: List[Dict[str, str]]
    ) -> bool:
        """
        Ensure that the combined length of all messages stays within the context window.
        We assume a 4,000-token total limit for gpt-3.5-turbo.
        """
        if not messages:
            return True
            
        total_tokens = 0
        for msg in messages:
            content = msg.get("content", "")
            total_tokens += self.estimate_tokens(content)

        # Reserve room for the response tokens
        max_input_tokens = 4000 - self.max_tokens
        return total_tokens <= max_input_tokens

    def truncate_messages_if_needed(
        self,
        messages: List[Dict[str, str]]
    ) -> List[Dict[str, str]]:
        """
        Truncate message history if it exceeds token limits.
        Always preserve system message if present.
        """
        if not messages or self.validate_message_length(messages):
            return messages

        # Separate system message from conversation
        system_msg = None
        conversation = []
        
        for msg in messages:
            if msg.get("role") == "system":
                system_msg = msg
            else:
                conversation.append(msg)

        # Keep reducing conversation until it fits
        while conversation and not self.validate_message_length(
            ([system_msg] if system_msg else []) + conversation
        ):
            conversation.pop(0)  # Remove oldest message

        # Reconstruct final message list
        final_messages = []
        if system_msg:
            final_messages.append(system_msg)
        final_messages.extend(conversation)
        
        return final_messages